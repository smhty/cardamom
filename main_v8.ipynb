{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8ec9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from camera import Camera\n",
    "from dorna2 import Dorna, Kinematic\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from IPython.display import display, clear_output\n",
    "import config\n",
    "import time\n",
    "from dorna_vision import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2f9802-e1cb-4898-8a7f-04257abcde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "helper functions\n",
    "\"\"\"\n",
    "# emergency\n",
    "def emergency_button_event(msg, union, robot, config):        \n",
    "    if config.emergency[0] in msg:\n",
    "        if robot.state == -1 and msg[config.emergency[0]] == config.emergency[1][1]: # init -> stopped\n",
    "            robot.state = 1\n",
    "        elif robot.state in [0, 1] and msg[config.emergency[0]] == config.emergency[1][0]: # (stopped, stopping) -> standby -> working\n",
    "            robot.set_alarm(1) # clear everything first\n",
    "            robot.state = 2\n",
    "        elif robot.state in [2, 3] and msg[config.emergency[0]] == config.emergency[1][1]: # (working, standby) -> stopping -> stop\n",
    "            robot.set_alarm(1) # clear everything first\n",
    "            robot.state = 0\n",
    "\n",
    "\n",
    "# classification of bad or good cardamom\n",
    "def img_classification(results, area_thr=None):\n",
    "    # init\n",
    "    cls = -1 # no pick\n",
    "    good = 0\n",
    "    \n",
    "    for result in results:\n",
    "        if result.masks is not None:\n",
    "            for i in range(len(result.masks)):\n",
    "                box = result.boxes[i]\n",
    "                mask = result.masks.xy[i]\n",
    "    \n",
    "                # conver masks to contour\n",
    "                cnt = np.int32([mask])\n",
    "                cnt = cnt.reshape(-1, 2)\n",
    "    \n",
    "                # check area\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area_thr and area <= min(area_thr) and area >= max(area_thr):\n",
    "                    continue\n",
    "                \n",
    "                # class\n",
    "                cls_tmp = box.cls.item()\n",
    "                # adjust the goods\n",
    "                good += cls_tmp\n",
    "        \n",
    "                # one bad found\n",
    "                if cls_tmp == 0:\n",
    "                    cls = cls_tmp\n",
    "                    return cls\n",
    "    \n",
    "    # one good at least, otherwise no pick\n",
    "    if good > 0:\n",
    "        cls = 1\n",
    "    \n",
    "    return cls\n",
    "\n",
    "\n",
    "# pick a value with highest probability which is also a float number\n",
    "def weight_classification(results, weight_thr):\n",
    "    cls = 0\n",
    "    conf = 0.2\n",
    "    weight = 0\n",
    "\n",
    "    # loopp over all the result\n",
    "    if results[0] is not None:\n",
    "        for result in results[0]:\n",
    "            try:\n",
    "                weight_tmp = float(result[1][0])\n",
    "                if result[1][1] >= conf:\n",
    "                    weight = weight_tmp\n",
    "                    conf = result[1][1]\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        print(\"weight: \", weight)\n",
    "        print(\"resuts: \", weight)\n",
    "        if weight >= weight_thr:\n",
    "            cls = 1        \n",
    "    return cls\n",
    "    \n",
    "# pick an item with highest confidence that is within the min and max area, retuen the center of the mass of the detected object\n",
    "def object_location(crop, robot, kinematic, T_cam_2_j4, camera, depth_frame, depth_int, results,  area_thr, xyz_thr):\n",
    "    sol = False\n",
    "    xyz_target_2_base = [0, 0, 0]\n",
    "    pxl = [0, 0]\n",
    "    cls = 0\n",
    "    \n",
    "    for result in results:\n",
    "        if result.masks is not None:\n",
    "            index = list(range(len(result.masks))) \n",
    "            random.shuffle(index) # reshuffle\n",
    "            \n",
    "            for i in index:\n",
    "                box = result.boxes[i]\n",
    "                mask = result.masks.xy[i]\n",
    "\n",
    "                # class\n",
    "                cls = box.cls.item()\n",
    "    \n",
    "                # conver masks to contour\n",
    "                cnt = np.int32([mask])\n",
    "                cnt = cnt.reshape(-1, 2)\n",
    "    \n",
    "                # check area\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area <= min(area_thr) or area >= max(area_thr):\n",
    "                    continue\n",
    "    \n",
    "                # center in pixel\n",
    "                M = cv2.moments(cnt)\n",
    "                # Calculate centroid (center) of the contour\n",
    "                pxl = crop.pxl_to_orig([int(M['m10'] / M['m00']), int(M['m01'] / M['m00'])])\n",
    "\n",
    "                # convert pixel to the original\n",
    "                # xyz_target to robot\n",
    "                xyz_target_2_cam, _ = camera.xyz(pxl, depth_frame, depth_int)\n",
    "                T_target_2_cam = np.eye(4)\n",
    "                T_target_2_cam[:3, 3] = np.ravel(xyz_target_2_cam)\n",
    "                \n",
    "                # current joint and pose\n",
    "                joint = robot.get_all_joint()\n",
    "                T_j4_2_base = kinematic.Ti_r_world(i=5, joint=joint[0:6])\n",
    "                \n",
    "                # target_2_base\n",
    "                T_target_2_base = np.matmul(T_j4_2_base, np.matmul(T_cam_2_j4, T_target_2_cam) )\n",
    "                xyz_target_2_base =T_target_2_base[:3, 3].flatten().tolist()[0] \n",
    "    \n",
    "                # check xyz\n",
    "                if any([xyz_target_2_base[i] <= min(xyz_thr[i]) or xyz_target_2_base[i] >= max(xyz_thr[i]) for i in range(len(xyz_target_2_base))]):\n",
    "                    continue\n",
    "                \n",
    "                # break the loop\n",
    "                sol = True\n",
    "                return cls, xyz_target_2_base, pxl, sol\n",
    "    \n",
    "    return cls, xyz_target_2_base, pxl, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3934f0b-0c6c-4593-ab02-9890091467a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.51 ðŸš€ Python-3.11.2 torch-2.3.1 CPU (Cortex-A76)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 38, 8400), (1, 32, 160, 160)) (6.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 7.7s, saved as 'yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3.torchscript' (13.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20240410...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running '/usr/local/lib/python3.11/dist-packages/ultralytics/pnnx yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3.torchscript ncnnparam=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.ncnn.param ncnnbin=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.ncnn.bin ncnnpy=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model_ncnn.py pnnxparam=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.param pnnxbin=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.bin pnnxpy=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model_pnnx.py pnnxonnx=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.onnx fp16=0 device=cpu inputshape=\"[1, 3, 640, 640]\"'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pnnxparam = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.param\n",
      "pnnxbin = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.bin\n",
      "pnnxpy = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model_pnnx.py\n",
      "pnnxonnx = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.pnnx.onnx\n",
      "ncnnparam = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.ncnn.param\n",
      "ncnnbin = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model.ncnn.bin\n",
      "ncnnpy = yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model/model_ncnn.py\n",
      "fp16 = 0\n",
      "optlevel = 2\n",
      "device = cpu\n",
      "inputshape = [1,3,640,640]f32\n",
      "inputshape2 = \n",
      "customop = \n",
      "moduleop = \n",
      "############# pass_level0\n",
      "inline module = ultralytics.nn.modules.block.Bottleneck\n",
      "inline module = ultralytics.nn.modules.block.C2f\n",
      "inline module = ultralytics.nn.modules.block.DFL\n",
      "inline module = ultralytics.nn.modules.block.Proto\n",
      "inline module = ultralytics.nn.modules.block.SPPF\n",
      "inline module = ultralytics.nn.modules.conv.Concat\n",
      "inline module = ultralytics.nn.modules.conv.Conv\n",
      "inline module = ultralytics.nn.modules.head.Segment\n",
      "inline module = ultralytics.nn.modules.block.Bottleneck\n",
      "inline module = ultralytics.nn.modules.block.C2f\n",
      "inline module = ultralytics.nn.modules.block.DFL\n",
      "inline module = ultralytics.nn.modules.block.Proto\n",
      "inline module = ultralytics.nn.modules.block.SPPF\n",
      "inline module = ultralytics.nn.modules.conv.Concat\n",
      "inline module = ultralytics.nn.modules.conv.Conv\n",
      "inline module = ultralytics.nn.modules.head.Segment\n",
      "\n",
      "----------------\n",
      "\n",
      "############# pass_level1\n",
      "############# pass_level2\n",
      "############# pass_level3\n",
      "############# pass_level4\n",
      "############# pass_level5\n",
      "############# pass_ncnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success âœ… 3.5s, saved as 'yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model' (12.6 MB)\n",
      "\n",
      "Export complete (14.0s)\n",
      "Results saved to \u001b[1m/home/dorna/cardamom\u001b[0m\n",
      "Predict:         yolo predict task=segment model=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model imgsz=640  \n",
      "Validate:        yolo val task=segment model=yolov8n-seg_cardamom_good_bad_nano_tile_null_removed_v3_ncnn_model imgsz=640 data=/content/Cardamom-good-bad--24/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "[2024/09/30 10:46:15] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize model and export it to ncnn formt\n",
    "\"\"\"\n",
    "# Load a YOLOv8n PyTorch model\n",
    "model = YOLO(config.trained_model)\n",
    "\n",
    "# Export the model to NCNN format\n",
    "exported_model = model.export(format=\"ncnn\")  # creates 'yolov8n_ncnn_model'\n",
    "\n",
    "# Load the exported NCNN model\n",
    "net = YOLO(exported_model, task=\"segment\")\n",
    "\n",
    "# ocr model\n",
    "ocr = PaddleOCR(use_angle_cls=False, lang='en')  # Disable text orientation classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74da7e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera robot connected:  True\n",
      "ground connected:  True\n",
      "Robot connected:  True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize camera, robot and the inverse kinematic engine\n",
    "\"\"\"\n",
    "# camera on robot\n",
    "camera_robot = Camera()\n",
    "print(\"Camera robot connected: \", camera_robot.connect(serial_number=config.camera_robot_sn, preset_path=config.camera_robot_preset_path, exposure=config.camera_robot_exposure, filter={}))\n",
    "camera_robot.set_exposure(config.camera_robot_exposure)\n",
    "\n",
    "# camera ground\n",
    "camera_ground = Camera()\n",
    "print(\"ground connected: \", camera_ground.connect(serial_number=config.camera_ground_sn, preset_path=config.camera_ground_preset_path, filter={}))\n",
    "\n",
    "# Robot\n",
    "robot = Dorna()\n",
    "robot.state = -1 # standby\n",
    "robot.add_event(target=emergency_button_event, kwargs={\"robot\": robot, \"config\": config})\n",
    "print(\"Robot connected: \", robot.connect(config.robot_ip))\n",
    "\n",
    "# kinematics\n",
    "kinematic = Kinematic(config.robot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8a07b-01cd-43d7-8b41-e7a287412472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "main loop\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "tare_counter = config.tare_cycle # number of time an item has been weighted\n",
    "save_img = 0 # number of images to save\n",
    "stat = {\"try\": 0, \"picked\": 0, \"failed\":0,  \"good\":0, \"bad\":0, \"time_passed\":0, \"avg_time\":0} # stat\n",
    "consecutive_failiure_counter = 0\n",
    "consecutive_mix = 0\n",
    "display_result = True # display images or not\n",
    "\n",
    "while True:\n",
    "    if robot.state == 0: # stopping -> stopped\n",
    "        robot.set_alarm(0) # clear alarm\n",
    "        robot.play_list(cmd_list=config.alarm_init)\n",
    "        robot.state = 1 # stopped\n",
    "    \n",
    "    elif robot.state == 2: # standby -> working\n",
    "        robot.set_alarm(0) # clear alarm\n",
    "        robot.play_list(cmd_list=config.work_init)\n",
    "        robot.state = 3 # stopped\n",
    "\n",
    "    elif robot.state == 3:\n",
    "        # update time\n",
    "        stat[\"time_passed\"] = time.time()-start_time\n",
    "        stat[\"avg_time\"] = stat[\"time_passed\"] /max(1,stat[\"picked\"])\n",
    "        print(\"stat: \", stat)\n",
    "        \n",
    "        \"\"\"\n",
    "        failed counter\n",
    "        \"\"\"\n",
    "        if consecutive_failiure_counter > config.bin_image_thr and consecutive_mix < config.mix_thr:\n",
    "            consecutive_failiure_counter = 0 # restart\n",
    "            robot.play_list(cmd_list=config.bin_mix)\n",
    "            consecutive_mix += 1 # update consecutive mix\n",
    "            continue\n",
    "    \n",
    "        \"\"\"\n",
    "        tare cycle\n",
    "        \"\"\"\n",
    "        if tare_counter >= config.tare_cycle:\n",
    "            tare_counter = 0\n",
    "            robot.play_list(cmd_list=config.tare)\n",
    "            continue\n",
    "        \n",
    "        \"\"\"\n",
    "        search for candidate\n",
    "        \"\"\"\n",
    "        robot.play_list(cmd_list=config.bin_image) # bin region\n",
    "        depth_frame, _, _, _, _, color_img, depth_int, _, _= camera_robot.get_all() # camera data\n",
    "        crop = util.Crop(color_img, config.bin_roi, rot=True)\n",
    "        color_img_mask = crop.cropped_img\n",
    "        \n",
    "        results = net(color_img_mask, half=True, conf=config.detection_conf, max_det=config.max_det, verbose=False) # detection\n",
    "        cls, xyz_target_2_base, pxl, sol = object_location(crop, robot, kinematic, config.T_cam_2_j4, camera_robot, depth_frame, depth_int, results, config.area_thr, config.xyz_thr) # picking candidate\n",
    "    \n",
    "        \n",
    "        \"\"\"\n",
    "        Display\n",
    "        \"\"\"\n",
    "        if display_result:\n",
    "            # Clear the previous output\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(cv2.cvtColor(results[0].plot(boxes=True, masks=False), cv2.COLOR_BGR2RGB)) # Display the image\n",
    "            plt.axis('off')  # Turn off axis\n",
    "            display(plt.gcf())  # Display the updated plot\n",
    "            plt.close() # release the memory\n",
    "    \n",
    "        #sol = False\n",
    "        if not sol: # no candidate\n",
    "            consecutive_failiure_counter += 1\n",
    "            continue\n",
    "        consecutive_failiure_counter = 0 # reset counter\n",
    "        consecutive_mix = 0 # reset counter\n",
    "    \n",
    "        \"\"\"\n",
    "        save image\n",
    "        \"\"\"\n",
    "        if save_img > 0: #\n",
    "            cv2.imwrite(\"img/\"+str(time.time())+\".jpg\", color_img)\n",
    "            save_img -= 1\n",
    "        \n",
    "        \"\"\"\n",
    "        picking\n",
    "        \"\"\"\n",
    "        config.pick[0] = {**config.pick[0], **{\"x\": xyz_target_2_base[0], \"y\": xyz_target_2_base[1], \"z\": xyz_target_2_base[2]+config.tcp_length+8}} # adjust pick xyz\n",
    "        robot.play_list(cmd_list=config.pick) # pick\n",
    "        stat[\"try\"] += 1 # update stat\n",
    "        \n",
    "        \"\"\"\n",
    "        bad after pick\n",
    "        \"\"\"\n",
    "        if cls == 0: # bad\n",
    "            robot.play_list(cmd_list=config.bad_bin_after_pick) # drop\n",
    "            stat[\"bad\"] += 1 # update stat\n",
    "            continue\n",
    "        \n",
    "        \"\"\"\n",
    "        check successful pick\n",
    "        \"\"\"\n",
    "        robot.play_list(cmd_list=config.quality)\n",
    "        _, _, _, _, _, color_img, _, _, _= camera_ground.get_all() # camera data\n",
    "        crop = util.Crop(color_img, config.quality_roi, rot=False)\n",
    "        successful_pick_img = crop.cropped_img # mask\n",
    "    \n",
    "        \n",
    "        # form one image\n",
    "        results = net(successful_pick_img, half=True, conf=config.detection_conf, verbose=False) # detection\n",
    "        cls = img_classification(results, config.area_thr) # quality decision\n",
    "    \n",
    "        \"\"\"\n",
    "        Display\n",
    "        \"\"\"\n",
    "        if display_result:\n",
    "            # Clear the previous output\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(cv2.cvtColor(results[0].plot(boxes=True, masks=False), cv2.COLOR_BGR2RGB)) # Display the image\n",
    "            plt.axis('off')  # Turn off axis\n",
    "            display(plt.gcf())  # Display the updated plot\n",
    "            plt.close() # release the memory\n",
    "    \n",
    "        if cls == -1: # no pick\n",
    "            stat[\"failed\"] += 1\n",
    "            continue\n",
    "        elif cls == 0: # bad\n",
    "            robot.play_list(cmd_list=config.bad_bin_after_quality) # drop\n",
    "            stat[\"picked\"] += 1\n",
    "            stat[\"bad\"] += 1\n",
    "            continue\n",
    "    \n",
    "        \"\"\"\n",
    "        quality check: multi bottom\n",
    "        \"\"\"\n",
    "        if config.quality_more[\"multi_bottom\"]:\n",
    "            # takes 4 images\n",
    "            color_img_mask_list = []\n",
    "            for j5 in [-30, 30, 90]:\n",
    "                robot.jmove(rel=0, j5=j5, vel=250, accel=4000, jerk=10000)\n",
    "                robot.sleep(0.2)\n",
    "                _, _, _, _, _, color_img, _, _, _= camera_ground.get_all() # camera data\n",
    "                crop = util.Crop(color_img, config.quality_roi, rot=False)\n",
    "                color_img_mask_list.append(crop.cropped_img) # mask\n",
    "        \n",
    "            \n",
    "            # form larger image\n",
    "            color_img_mask = np.vstack([np.hstack([color_img_mask_list[0], color_img_mask_list[1]]), np.hstack([color_img_mask_list[2], successful_pick_img])])\n",
    "            results = net(color_img_mask, half=True, conf=config.detection_conf, verbose=False) # detection\n",
    "            cls = img_classification(results, config.area_thr) # quality decision\n",
    "    \n",
    "            \"\"\"\n",
    "            Display\n",
    "            \"\"\"\n",
    "            if display_result:\n",
    "                # Clear the previous output\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(cv2.cvtColor(results[0].plot(boxes=True, masks=False), cv2.COLOR_BGR2RGB)) # Display the image\n",
    "                plt.axis('off')  # Turn off axis\n",
    "                display(plt.gcf())  # Display the updated plot\n",
    "                plt.close() # release the memory\n",
    "            \n",
    "            \"\"\"\n",
    "            result after quality check\n",
    "            \"\"\"\n",
    "            if cls == -1: # no pick\n",
    "                stat[\"failed\"] += 1\n",
    "                continue\n",
    "            elif cls == 0: # bad\n",
    "                robot.play_list(cmd_list=config.bad_bin_after_quality) # drop\n",
    "                stat[\"picked\"] += 1\n",
    "                stat[\"bad\"] += 1\n",
    "                continue\n",
    "    \n",
    "        \"\"\"\n",
    "        quality check_2:second top\n",
    "        \"\"\"\n",
    "        robot.play_list(cmd_list=config.quality_2)\n",
    "        if config.quality_more[\"second_top\"]:\n",
    "            # capture data\n",
    "            _, _, _, _, _, color_img, _, _, _= camera_robot.get_all() # camera data\n",
    "            crop = util.Crop(color_img, config.quality_2_roi, rot=False)\n",
    "            color_img_mask = crop.cropped_img\n",
    "        \n",
    "            \n",
    "            # quality check\n",
    "            results = net(color_img_mask, half=True, conf=config.detection_conf, verbose=False) # detection\n",
    "            cls = img_classification(results, config.area_thr) # quality decision\n",
    "    \n",
    "            \"\"\"\n",
    "            Display\n",
    "            \"\"\"\n",
    "            if display_result:\n",
    "                # Clear the previous output\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(cv2.cvtColor(results[0].plot(boxes=True, masks=False), cv2.COLOR_BGR2RGB)) # Display the image\n",
    "                plt.axis('off')  # Turn off axis\n",
    "                display(plt.gcf())  # Display the updated plot\n",
    "                plt.close() # release the memory\n",
    "        else:\n",
    "            cls = 1\n",
    "        \n",
    "        if cls != 0:\n",
    "            \"\"\"\n",
    "            weight\n",
    "            \"\"\"\n",
    "            robot.play_list(cmd_list=config.weight)\n",
    "            \n",
    "            _, _, _, _, _, color_img, _, _, _= camera_robot.get_all() # camera data\n",
    "            color_img_mask = util.roi_mask(color_img, config.ocr_roi)\n",
    "            results = ocr.ocr(color_img_mask, cls=False)  # ocr\n",
    "            cls = weight_classification(results, config.weight_thr) # classification\n",
    "            \n",
    "            \"\"\"\n",
    "            Display\n",
    "            \"\"\"\n",
    "            if display_result:\n",
    "                # Clear the previous output\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(cv2.cvtColor(color_img_mask, cv2.COLOR_BGR2RGB)) # Display the image\n",
    "                plt.axis('off')  # Turn off axis\n",
    "                display(plt.gcf())  # Display the updated plot\n",
    "                plt.close() # release the memory\n",
    "            \n",
    "        \n",
    "        if cls <= 0: # bad\n",
    "            robot.play_list(cmd_list=config.drop_bad)\n",
    "            stat[\"bad\"] += 1 #update stat\n",
    "        else: # good\n",
    "            robot.play_list(cmd_list=config.drop_good[0:4])\n",
    "            stat[\"good\"] += 1 #update stat\n",
    "        \n",
    "        # increase weight counter\n",
    "        stat[\"picked\"] += 1 #update stat\n",
    "        tare_counter += 1 # update stat\n",
    "    else:\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574077f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Always close the camera and robot, once your application is over\n",
    "\"\"\"\n",
    "# terminate the session\n",
    "camera_ground.close()\n",
    "camera_robot.close()\n",
    "robot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd6257b-d7ad-451d-8114-2994f35478c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b0e58f-f848-4fb6-8092-d67dd4c413b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2\n",
    "#module 'pyrealsense2' has no attribute 'stream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c034b4-4b9c-4eb2-8de9-79ac61fea360",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<module 'pyrealsense2' (<_frozen_importlib_external.NamespaceLoader object at 0x7fff30dfe510>)> is a built-in module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyrealsense2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyrealsense2\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/package/package_importer.py:698\u001b[0m, in \u001b[0;36m_patched_getfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _package_imported_modules:\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _package_imported_modules[\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_getfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/inspect.py:901\u001b[0m, in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is a built-in module\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mobject\u001b[39m))\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isclass(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: <module 'pyrealsense2' (<_frozen_importlib_external.NamespaceLoader object at 0x7fff30dfe510>)> is a built-in module"
     ]
    }
   ],
   "source": [
    "import pyrealsense2\n",
    "import inspect\n",
    "\n",
    "print(inspect.getfile(pyrealsense2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4dcae6-0fee-4f5e-8e64-50195af7a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'pyrealsense2' (<_frozen_importlib_external.NamespaceLoader object at 0x7fff30dfe510>)>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if 'pyrealsense2' in sys.modules:\n",
    "    print(sys.modules['pyrealsense2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8ae19-1c52-4127-80b5-e6c5bd30d239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
